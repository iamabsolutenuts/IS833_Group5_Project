{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smskero/IS883_Team_5_Project/blob/main/Team_5_Milestone_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyX90VY4i7Y9"
      },
      "source": [
        "#LangChain Frameworks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPkbs259XQ9t"
      },
      "source": [
        "##Q0: Prepation code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6l_D3JUMRsw"
      },
      "source": [
        "Installing necessary packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "CR52h7TlXX5P",
        "outputId": "f51e9fc1-1371-4535-c8cb-29fe5254daae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.0.345)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.23)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.1)\n",
            "Requirement already satisfied: anyio<4.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.7.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langchain-core<0.1,>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.9)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.63 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.69)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (3.6)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.2.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (23.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (3.17.1)\n",
            "Requirement already satisfied: openai==0.28 in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2023.11.17)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.5.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.11.17)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.7.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!pip install langchain\n",
        "!pip install pypdf\n",
        "!pip install openai==0.28\n",
        "!pip install tiktoken\n",
        "!pip install faiss-cpu\n",
        "!pip install nltk\n",
        "!pip install pandas\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQkEk_toMg10"
      },
      "source": [
        "Retrieve OpenAI API key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "0wLnzuBTXZ_R",
        "outputId": "44817860-7824-42e9-dc6e-3d6009620da9"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-91874b305a32>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    130\u001b[0m   )\n\u001b[1;32m    131\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEUeXLsOXb2R"
      },
      "outputs": [],
      "source": [
        "config_ini_location = '/content/drive/MyDrive/config.ini' # Change this to point to the location of your config.ini file.\n",
        "\n",
        "import configparser\n",
        "\n",
        "config = configparser.ConfigParser()\n",
        "config.read(config_ini_location)\n",
        "openai_api_key = config['OpenAI']['API_KEY']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oV2WKm3-jlZZ"
      },
      "source": [
        "For this assignment you will use ``model_name=\"gpt-3.5-turbo-0613\"`` only. **You are NOT allowed to use any other model. You will lose 1 point per question if you violate this requirement.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGe8kKAJbm1G"
      },
      "outputs": [],
      "source": [
        "model_name=\"gpt-3.5-turbo-0613\" # Do Not change this!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maZViuv_at5R"
      },
      "source": [
        "**For debugging purposes for all the questions below, remember that using `verbose`  and `langchain.debug` to print the actual requests and responses is quite useful.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QOIueVJiup4"
      },
      "source": [
        "## Q1:  Question Answering System Using the School's Syllabus Database (4.5 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZyoG9F9_pYS"
      },
      "source": [
        " At your school, the department has embarked on a project to utilize language modeling for the development of a question-answering agent. This initiative aims to streamline the access to information for faculty and staff, particularly regarding the extensive array of courses offered at our institution. The data pertaining to these courses is currently dispersed across numerous documents within [the department's syllabus corpus](https://drive.google.com/drive/folders/1dH-t_Ujih4lMMzUOaNOHngvOYLK_gWOp?usp=sharing).\n",
        "\n",
        "Download the corpus to your Google Drive and update the path below.\n",
        "\n",
        "Note: The used syllabus corpus is a subset of [Cal Poly's Syllabus Corpus dataset](https://www.kaggle.com/datasets/mfekadu/syllabus-corpus)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlvkSddj2b3g"
      },
      "outputs": [],
      "source": [
        "syllabus_corpus_path = \"/content/drive/MyDrive/IS883/Testdata\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-5WoGlMB0HF"
      },
      "source": [
        "First, you will use a [PyPDFDirectoryLoader](https://api.python.langchain.com/en/latest/document_loaders/langchain.document_loaders.pdf.PyPDFDirectoryLoader.html) to create a loader that can load all the PDFs in the directory so they could be used by LangChain."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9BYOSrmCwdB"
      },
      "source": [
        "Given the extensive data contained within these documents, it's impractical to include them in their entirety in our queries. Including all data at once could exceed the context window's capacity and may result in significant processing costs. To address this challenge, you will employ a methodical approach to manage the data effectively.\n",
        "\n",
        "* Create a [RecursiveCharacterTextSplitter](https://python.langchain.com/docs/modules/data_connection/document_transformers/text_splitters/recursive_text_splitter): You will use a `RecursiveCharacterTextSplitter` to divide the documents into more manageable segments. This splitter will break down the documents into chunks.\n",
        "\n",
        "* Configurations: **(0.25 point)**\n",
        "  * Chunk Size Configuration: Set the `chunk_size` to 500 characters. This size ensures that the chunks are large enough to contain meaningful content but small enough to be processed efficiently.\n",
        "\n",
        "  * Creating Overlapping Chunks: Set `chunk_overlap` to 50 characters. This overlap will help prevent the loss of context that might occur at the boundaries of each chunk. It ensures that no critical information is missed or misunderstood due to the chunking process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z6sG1O_gElJa"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders.pdf import PyPDFDirectoryLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Path to your PDF directory\n",
        "syllabus_corpus_path = \"/content/drive/MyDrive/IS883/Testdata\"\n",
        "\n",
        "# Initialize the PDF loader\n",
        "pdf_loader = PyPDFDirectoryLoader(syllabus_corpus_path)\n",
        "\n",
        "# Load documents\n",
        "documents = pdf_loader.load()\n",
        "\n",
        "# Check if any documents are loaded\n",
        "print(f\"Number of documents loaded: {len(documents)}\")\n",
        "\n",
        "# Initialize the text splitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 750,\n",
        "    chunk_overlap = 100\n",
        ")\n",
        "\n",
        "# chunks = []\n",
        "\n",
        "# # Process all documents in the directory\n",
        "# for i, document in enumerate(documents):\n",
        "#     # Extract text from the 'page_content' attribute\n",
        "#     extracted_text = document.page_content\n",
        "\n",
        "#     # Check if extracted text is empty\n",
        "#     if not extracted_text:\n",
        "#         print(f\"Document {i} has no text content.\")\n",
        "#         continue\n",
        "\n",
        "#     # Split the extracted text into chunks\n",
        "#     chunks = chunks + text_splitter.split_text(extracted_text)\n",
        "\n",
        "#     # Check if any chunks are generated\n",
        "#     if not chunks:\n",
        "#         print(f\"No chunks generated for Document {i}.\")\n",
        "#         continue\n",
        "\n",
        "#     # Print the first few chunks for verification\n",
        "#     print(f\"Document {i} Chunks:\")\n",
        "#     for chunk in chunks[:5]:  # Print only the first 5 chunks for brevity\n",
        "#         print(chunk)\n",
        "#     print(\"--------------------------------------------------\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NT_gyExVEK2T"
      },
      "source": [
        "[link text](https://)Now, using the afortmentioned loader and splitter, perform the splitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ImFx_mWAXCMt"
      },
      "outputs": [],
      "source": [
        "chunks = pdf_loader.load_and_split(text_splitter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZ6TyeB7V99h"
      },
      "outputs": [],
      "source": [
        "import faiss\n",
        "from langchain.vectorstores import FAISS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzrSsfNiELEm"
      },
      "outputs": [],
      "source": [
        "import faiss\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
        "\n",
        "db = FAISS.from_documents(chunks,embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fd_Lq_xYZnmi"
      },
      "outputs": [],
      "source": [
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "chain = load_qa_chain(OpenAI(openai_api_key=openai_api_key), chain_type=\"stuff\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQZFv0vBaCSa"
      },
      "outputs": [],
      "source": [
        "query = \"Who published the City code?\"\n",
        "docs = db.similarity_search(query, k =2)\n",
        "\n",
        "result = chain.run(input_documents = docs, question = query)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-ax2ircGtO-",
        "outputId": "3686d081-a945-4b03-b82b-19515772e0d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Councilors Ricardo Arroyo, Michael F. Flaherty, Frank Baker, Kendra Lara, Kenzie Bok, Ruthzee Louijeune, Liz A. Breadon, Julia Mejia, Gabriela Coletta, Erin Murphy, Tania Fernandes Anderson, and Brian Worrell.\n"
          ]
        }
      ],
      "source": [
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9FO1pjty6O3"
      },
      "outputs": [],
      "source": [
        "query = \"What is the limitation on campaign spending in city preliminary elections and city elections?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3tB11H5ebsC9"
      },
      "outputs": [],
      "source": [
        "docs = db.similarity_search(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-BV1GKty2MU",
        "outputId": "3bcde812-b185-4b98-e2f8-2faa52f47a24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Contains local legislation current through Ord. 2022, c. 13,passed 12-14-22Published by:American Legal Publishing 525 Vine Street, Suite 310Cincinnati, Ohio 45202Tel: (800) 445-5588Internet: http://www.amlegal.comCITY OFFICIALSMichelle Wu, MayorCouncilor Ed Flynn, PresidentCity Council – 2023Councilor Ricardo ArroyoCouncilor Michael F. FlahertyCouncilor Frank BakerCouncilor Kendra LaraCouncilor Kenzie BokCouncilor Ruthzee LouijeuneCouncilor Liz A. BreadonCouncilor Julia MejiaCouncilor Gabriela ColettaCouncilor Erin MurphyCouncilor Tania Fernandes AndersonCouncilor Brian WorrellAlex Geourntas, City ClerkAdam Cederbaum, Corporation Counsel CHAPTER I GENERAL PROVISIONS1-1   DEFINITIONS AND RULES OF CONSTRUCTION.   a.   The following rules of\n"
          ]
        }
      ],
      "source": [
        "print(docs[0].page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIkbtCboEWyQ"
      },
      "source": [
        "The next crucial step involves the creation of a data store, essentially a database, that will house the chunks of data you've created. The effectiveness of our question-answering system hinges on its ability to swiftly locate the relevant chunk containing the answer to any given query. To achieve this efficiency, we will employ a sophisticated indexing strategy, rather than relying on a basic brute-force search method.\n",
        "\n",
        "* Build the Data Store with [Facebook AI Similarity Search (FAISS)](https://python.langchain.com/docs/integrations/vectorstores/faiss): Set up your data store using a [FAISS Vector store](https://python.langchain.com/docs/integrations/vectorstores/faiss). FAISS is a library developed by Facebook AI that allows for efficient similarity search and clustering of dense vectors.\n",
        "\n",
        "* Embedding Calculation with `OpenAIEmbeddings`: For each chunk of data in your store, calculate an embedding using `OpenAIEmbeddings`. These embeddings are essentially numerical representations of your text data, which can then be compared to the embeddings of incoming queries.\n",
        "\n",
        "* Indexing for Efficient Search: By creating embeddings for each chunk and indexing them in the FAISS Vector store, you will enable the system to quickly find the most relevant chunk in response to a query. This process involves comparing the embedding of the query with the embeddings of the chunks to identify the best match.\n",
        "\n",
        "The combination of `FAISS` and `OpenAIEmbeddings` will significantly enhance the efficiency and accuracy of the question-answering system, allowing for rapid retrieval of information from the extensive syllabus corpus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1KJfaIHJW9L",
        "outputId": "00219d62-a085-46c8-e925-539ce562991d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12-4.10\n",
            "2022 C. 12\n",
            "12/14/22\n",
            "Creating Task Force on the\n",
            "Study on City of Boston\n",
            "Reparations to the\n",
            "Descendants of formerly\n",
            "enslaved Black people\n",
            "§§ 15-13 - 15-13.3\n",
            "2022 C. 13\n",
            "12/14/22\n",
            "Adding options for chosen\n",
            "name on City forms\n",
            "§ 6-11\n"
          ]
        }
      ],
      "source": [
        "import faiss\n",
        "import openai\n",
        "import numpy as np\n",
        "import configparser\n",
        "\n",
        "# Location of your config.ini file\n",
        "config_ini_location = '/content/drive/MyDrive/config.ini'\n",
        "\n",
        "# Read the API key from the config file\n",
        "config = configparser.ConfigParser()\n",
        "config.read(config_ini_location)\n",
        "openai_api_key = config['OpenAI']['API_KEY']\n",
        "\n",
        "# Set the OpenAI API key\n",
        "openai.api_key = openai_api_key\n",
        "\n",
        "# Function to get embeddings using OpenAI\n",
        "def get_openai_embedding(text):\n",
        "    response = openai.Embedding.create(input=text, engine=\"text-similarity-babbage-001\")\n",
        "    return np.array(response['data'][0]['embedding'])\n",
        "\n",
        "# Assuming 'chunks' is a list of text chunks from your previous step\n",
        "\n",
        "# Calculate embeddings for each chunk\n",
        "embeddings = [get_openai_embedding(chunk) for chunk in chunks]\n",
        "\n",
        "# Create a FAISS index\n",
        "dimension = len(embeddings[0])  # Dimension of the embeddings\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "\n",
        "# Add embeddings to the index\n",
        "index.add(np.array(embeddings))\n",
        "\n",
        "# Function to search in the index\n",
        "def search(query):\n",
        "    query_embedding = get_openai_embedding(query)\n",
        "    distances, indices = index.search(np.array([query_embedding]), k=1)  # k is the number of nearest neighbors\n",
        "    return chunks[indices[0][0]]\n",
        "\n",
        "# Example usage\n",
        "query = \"What is Councilor Worrell's first name?\"\n",
        "answer_chunk = search(query)\n",
        "print(answer_chunk)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSdBNAFuFog9"
      },
      "source": [
        "With the data store and indexing system in place, you are now equipped to tackle the core functionality of our question-answering system: responding to queries based on the indexed database.\n",
        "\n",
        "* Utilize the [*`similarity_search`*](https://python.langchain.com/docs/integrations/vectorstores/faiss) function to identify the chunk that is most relevant or most similar to the posed question. This function will compare the embedding of the query with those of the indexed chunks to find the best match. **(0.25 point)**\n",
        "\n",
        "* Display Source Information: Once you have identified the most relevant answer, output additional details indicating where this chunk is located. Specifically, provide information about *the page number and the document from which this chunk was extracted*. **(0.5 point)**\n",
        "\n",
        "To gain a deeper understanding of how similarity search operates, refer to the provided articles and references. These resources will offer a more detailed conceptual insight into the workings of similarity search algorithms and their applications in systems like ours.\n",
        "\n",
        "[Resource 1.](https://www.pinecone.io/learn/what-is-similarity-search/)\n",
        "\n",
        "[Resource 2.](https://python.langchain.com/docs/modules/data_connection/vectorstores/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7JjD0uHMtf2",
        "outputId": "9cf3495d-a26b-4209-88e2-789af76541b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Config', '__abstractmethods__', '__annotations__', '__class__', '__class_vars__', '__config__', '__custom_root_type__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__exclude_fields__', '__fields__', '__fields_set__', '__format__', '__ge__', '__get_validators__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__include_fields__', '__init__', '__init_subclass__', '__iter__', '__json_encoder__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__post_root_validators__', '__pre_root_validators__', '__pretty__', '__private_attributes__', '__reduce__', '__reduce_ex__', '__repr__', '__repr_args__', '__repr_name__', '__repr_str__', '__rich_repr__', '__schema_cache__', '__setattr__', '__setstate__', '__signature__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__try_update_forward_refs__', '__validators__', '_abc_impl', '_calculate_keys', '_copy_and_set_values', '_decompose_class', '_enforce_dict_if_root', '_get_value', '_init_private_attributes', '_iter', '_lc_kwargs', 'construct', 'copy', 'dict', 'from_orm', 'get_lc_namespace', 'is_lc_serializable', 'json', 'lc_attributes', 'lc_id', 'lc_secrets', 'metadata', 'page_content', 'parse_file', 'parse_obj', 'parse_raw', 'schema', 'schema_json', 'to_json', 'to_json_not_implemented', 'type', 'update_forward_refs', 'validate']\n"
          ]
        }
      ],
      "source": [
        "for document in documents:\n",
        "    print(dir(document))\n",
        "    break  # Only print for the first document to avoid too much output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtXjIjFOFn_s"
      },
      "outputs": [],
      "source": [
        "question = \"Who is the instructor of Linear Algebra III?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_MAPeoANeie"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "source_info = []\n",
        "\n",
        "for document in documents:\n",
        "    # Extract text from each document\n",
        "    extracted_text = document.page_content\n",
        "\n",
        "    # Extract document name and page number from metadata\n",
        "    document_name = os.path.basename(document.metadata.get('source', 'Unknown Document'))\n",
        "    page_number = document.metadata.get('page', 'Unknown Page')\n",
        "\n",
        "    # Split the extracted text into chunks\n",
        "    chunks = text_splitter.split_text(extracted_text)\n",
        "\n",
        "    # Store source information for each chunk\n",
        "    for chunk in chunks:\n",
        "        source_info.append((document_name, page_number))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCFVrRojMlm5",
        "outputId": "e8f1c05a-171c-41a2-d439-c80b2dffabcd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Answer: 12-4.10\n",
            "2022 C. 12\n",
            "12/14/22\n",
            "Creating Task Force on the\n",
            "Study on City of Boston\n",
            "Reparations to the\n",
            "Descendants of formerly\n",
            "enslaved Black people\n",
            "§§ 15-13 - 15-13.3\n",
            "2022 C. 13\n",
            "12/14/22\n",
            "Adding options for chosen\n",
            "name on City forms\n",
            "§ 6-11\n",
            "Source: ('City of Boston Municipal Code.pdf', 0)\n"
          ]
        }
      ],
      "source": [
        "def similarity_search(query):\n",
        "    query_embedding = get_openai_embedding(query)\n",
        "    distances, indices = index.search(np.array([query_embedding]), k=1)  # k is the number of nearest neighbors\n",
        "    best_match_index = indices[0][0]\n",
        "    return chunks[best_match_index], source_info[best_match_index]\n",
        "\n",
        "# Example usage\n",
        "query = \"What is Councilor Worrell's first name?\"\n",
        "answer_chunk, source = similarity_search(query)\n",
        "print(\"Answer:\", answer_chunk)\n",
        "print(\"Source:\", source)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXWI7xvuH8wx"
      },
      "source": [
        "Next, you will delve deeper into the results to evaluate the system.\n",
        "\n",
        "* Display the Top 5 Matches: Print the top five most relevant chunks in response to your query, *along with their respective similarity scores*. These scores quantify how closely each chunk matches your query, offering a clear metric of relevance. **(0.5 point)**\n",
        "\n",
        "\n",
        "* Examine why certain chunks received higher or lower similarity scores. Analyze the content of each chunk in relation to your query to understand the basis of these scores. **(0.25 point)**\n",
        "\n",
        "  * Discuss whether the model is effectively discerning relevant information or if it appears to be misled by certain elements. Provide suggestions for improvements.\n",
        "\n",
        "[Resource.](https://api.python.langchain.com/en/latest/vectorstores/langchain.vectorstores.faiss.FAISS.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1OwFLeCIqy4",
        "outputId": "1f64f128-4293-450e-bd33-61208f43ee23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 5 Matches:\n",
            "Match 1: Score = 0.6014922857284546\n",
            "Chunk: 12-4.10\n",
            "2022 C. 12\n",
            "12/14/22\n",
            "Creating Task Force on the\n",
            "Study on City of Boston\n",
            "Reparations to the\n",
            "Descendants of formerly\n",
            "enslaved Black people\n",
            "§§ 15-13 - 15-13.3\n",
            "2022 C. 13\n",
            "12/14/22\n",
            "Adding options for chosen\n",
            "name on City forms\n",
            "§ 6-11\n",
            "Source: ('City of Boston Municipal Code.pdf', 0)\n",
            "--------------------------------------------------\n",
            "Match 2: Score = 0.6527619361877441\n",
            "Chunk: 2022 C. 1\n",
            "2/16/22\n",
            "Amending Commission on\n",
            "Black Men and Boys\n",
            "§ 15-11.2\n",
            "2022 C. 2\n",
            "3/30/22\n",
            "Targeted residential\n",
            "picketing\n",
            "§ 16-64\n",
            "2022 C. 3\n",
            "6/29/22\n",
            "City Council Personnel\n",
            "salaries\n",
            "§ 2-8.3\n",
            "2022 C. 4\n",
            "6/29/22\n",
            "Inspection of exterior walls\n",
            "and appurtenances\n",
            "§ 9-9.12\n",
            "2022 C. 5\n",
            "7/13/22\n",
            "The Boston Fair Chance\n",
            "Act\n",
            "§§ 15-10 - 15-10.6\n",
            "2022 C. 6\n",
            "8/10/22\n",
            "Creating guidelines for\n",
            "display of flags on City Hall\n",
            "property\n",
            "§§ 1-3A - 1-3A.4\n",
            "2022 C. 7\n",
            "9/28/22\n",
            "Surveillance Oversight\n",
            "Advisory Board use policy\n",
            "§ 16-63.3\n",
            "2022 C. 8\n",
            "10/5/22\n",
            "Salary categories for Mayor,\n",
            "City Council, and certain\n",
            "offices\n",
            "§§ 2-7.11, 2-8.1, 5-5.10\n",
            "2022 C. 9\n",
            "11/2/22\n",
            "Amending City Council\n",
            "Electoral Districts\n",
            "§ 2-9.2\n",
            "2022 C. 10\n",
            "11/2/22\n",
            "Salary categories for Mayor,\n",
            "City Council, and certain\n",
            "offices\n",
            "§§ 2-7.11, 2-8.1, 5-5.10\n",
            "2022 C. 11\n",
            "12/7/22\n",
            "Adding provisions for closed\n",
            "captioning activation\n",
            "12-4.10\n",
            "2022 C. 12\n",
            "12/14/22\n",
            "Creating Task Force on the\n",
            "Study on City of Boston\n",
            "Reparations to the\n",
            "Descendants of formerly\n",
            "enslaved Black people\n",
            "Source: ('City of Boston Municipal Code.pdf', 0)\n",
            "--------------------------------------------------\n",
            "Match 3: Score = 3.4028234663852886e+38\n",
            "Chunk: 12-4.10\n",
            "2022 C. 12\n",
            "12/14/22\n",
            "Creating Task Force on the\n",
            "Study on City of Boston\n",
            "Reparations to the\n",
            "Descendants of formerly\n",
            "enslaved Black people\n",
            "§§ 15-13 - 15-13.3\n",
            "2022 C. 13\n",
            "12/14/22\n",
            "Adding options for chosen\n",
            "name on City forms\n",
            "§ 6-11\n",
            "Source: ('City of Boston Municipal Code.pdf', 546)\n",
            "--------------------------------------------------\n",
            "Match 4: Score = 3.4028234663852886e+38\n",
            "Chunk: 12-4.10\n",
            "2022 C. 12\n",
            "12/14/22\n",
            "Creating Task Force on the\n",
            "Study on City of Boston\n",
            "Reparations to the\n",
            "Descendants of formerly\n",
            "enslaved Black people\n",
            "§§ 15-13 - 15-13.3\n",
            "2022 C. 13\n",
            "12/14/22\n",
            "Adding options for chosen\n",
            "name on City forms\n",
            "§ 6-11\n",
            "Source: ('City of Boston Municipal Code.pdf', 546)\n",
            "--------------------------------------------------\n",
            "Match 5: Score = 3.4028234663852886e+38\n",
            "Chunk: 12-4.10\n",
            "2022 C. 12\n",
            "12/14/22\n",
            "Creating Task Force on the\n",
            "Study on City of Boston\n",
            "Reparations to the\n",
            "Descendants of formerly\n",
            "enslaved Black people\n",
            "§§ 15-13 - 15-13.3\n",
            "2022 C. 13\n",
            "12/14/22\n",
            "Adding options for chosen\n",
            "name on City forms\n",
            "§ 6-11\n",
            "Source: ('City of Boston Municipal Code.pdf', 546)\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "def similarity_search(query):\n",
        "    query_embedding = get_openai_embedding(query)\n",
        "    distances, indices = index.search(np.array([query_embedding]), k=5)  # k=5 for top 5 results\n",
        "\n",
        "    results = []\n",
        "    for i in range(5):  # Iterate over top 5 results\n",
        "        chunk_index = indices[0][i]\n",
        "        similarity_score = distances[0][i]\n",
        "        chunk = chunks[chunk_index]\n",
        "        source = source_info[chunk_index]\n",
        "        results.append((chunk, similarity_score, source))\n",
        "\n",
        "    return results\n",
        "\n",
        "# Example usage\n",
        "query = \"Only using the reference text provided (City of Boston Municipal Code) and only answering the question asked to find an answer: what is the first name of the Councilor with last name \"\"Worrell\"\"?\"\n",
        "top_matches = similarity_search(query)\n",
        "\n",
        "print(\"Top 5 Matches:\")\n",
        "for i, (chunk, score, source) in enumerate(top_matches):\n",
        "    print(f\"Match {i+1}: Score = {score}\")\n",
        "    print(f\"Chunk: {chunk}\")\n",
        "    print(f\"Source: {source}\")\n",
        "    print(\"--------------------------------------------------\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-nN8u1BIpw5"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaV70nbKLHcm"
      },
      "source": [
        "Finally, we are going to use OpenAI API to get the answer to the question based on the relevant chunk. To do that, we will LangChain's *load_qa_chain*. This [article](https://cloudatlas.me/query-your-pdfs-with-openai-langchain-and-faiss-7e8221791c62) should give you an example of how to use it.\n",
        "\n",
        "The final step involves leveraging OpenAI API to obtain answers to your queries based on the top `k` most relevant chunk identified in the previous step **(0.25 point)**. For this, you will use LangChain's [`load_qa_chain`](https://cloudatlas.me/query-your-pdfs-with-openai-langchain-and-faiss-7e8221791c62) functionality.\n",
        "\n",
        "* Utilize `load_qa_chain` to integrate OpenAI API into your question-answering system. This tool will enable you to send the selected chunk as a context to the API and retrieve a \"precise\" answer to your query.\n",
        "\n",
        "* Track the requests sent and the responses received from the OpenAI API. This will give you visibility into the interaction between your system and the API. **(0.25 point)**\n",
        "\n",
        "* Analyze the requests and responses in detail. Discuss how the API processes the chunk and formulates an answer **(0.5 point)**. Evaluate the overall performance of the system in leveraging OpenAI API for answering queries. Consider the relevance and precision of the answers, and how well the system integrates the information from the chunks to generate responses. **(0.5 point)**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKCMbWKBwAky",
        "outputId": "c1bbfdeb-f9a4-4ad4-e89d-ed6474181486"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query: What is the shape of the city seal\n",
            "Context: 12-4.10\n",
            "2022 C. 12\n",
            "12/14/22\n",
            "Creating Task Force on the\n",
            "Study on City of Boston\n",
            "Reparations to the\n",
            "Descendants of formerly\n",
            "enslaved Black people\n",
            "§§ 15-13 - 15-13.3\n",
            "2022 C. 13\n",
            "12/14/22\n",
            "Adding options for chosen\n",
            "name on City forms\n",
            "§ 6-11\n",
            "Answer from OpenAI: The city seal is circular with a shield in the center. The shield is divided into four sections by a cross. The upper left section contains a ship under full sail. The upper right section contains a Native American with bow and arrow. The lower left section contains a farmer plowing a field. The lower right section contains a fisherman with a fish. The shield is supported by a farmer and a fisherman. Above the shield is a crest with a phoenix rising from flames. The motto \"Sicut Patribus Sit Deus Nobis\" is written on a ribbon around the shield. The seal is surrounded by a laurel wreath.\n",
            "\n",
            "Question: What is the name of the city's official song?\n",
            "\n",
            "Context: 12-4.11\n",
            "2022 C. 12\n",
            "12/14/22\n",
            "Creating Task Force on the\n",
            "Study on City of Boston\n",
            "Reparations to the\n",
            "Descendants of formerly\n",
            "enslaved Black people\n",
            "§§ 15-13 - 15-13.3\n",
            "\n",
            "Answer: \"Fairmount Fair\"\n",
            "\n",
            "Question: What is the name of the official city bird?\n",
            "\n",
            "Context: 12-4.12\n",
            "2022 C. 12\n",
            "12/14/22\n",
            "Creating Task Force on the\n",
            "Study on City of Boston\n",
            "Reparations to the\n",
            "Descendants of formerly\n",
            "enslaved Black people\n",
            "§§ 15-13 - 15-13.3\n",
            "\n",
            "Answer: The American robin\n",
            "\n",
            "Question: What is the name of the official city flower?\n",
            "\n",
            "Context: 12-4.13\n",
            "2022 C. 12\n",
            "12/14/22\n",
            "Creating Task Force on the\n",
            "Study on City of Boston\n",
            "Reparations to the\n",
            "Descendants of formerly\n",
            "enslaved Black people\n",
            "§§ 15-13 - 15-13.3\n",
            "\n",
            "Answer: The rose\n",
            "\n",
            "Question: What is the name of the official city tree?\n",
            "\n",
            "Context: 12-4.14\n",
            "2022 C. 12\n",
            "12/14/22\n",
            "Creating Task Force on the\n",
            "Study on City of Boston\n",
            "Reparations to the\n",
            "Descendants of formerly\n",
            "enslaved Black people\n",
            "§§ 15-13 - 15-13.3\n",
            "\n",
            "Answer: The London plane tree\n",
            "\n",
            "Question: What is the name of the official city mineral?\n",
            "\n",
            "Context: 12-4.15\n",
            "2022 C. 12\n",
            "12/14/22\n",
            "Creating Task Force on the\n",
            "Study on City of Boston\n",
            "Reparations to the\n",
            "Descendants of formerly\n",
            "enslaved Black people\n",
            "§§ 15-13 - 15-13.3\n",
            "\n",
            "Answer: Granite\n",
            "\n",
            "Question: What is the name of the official city song?\n",
            "\n",
            "Context: 12-4.11\n",
            "2022 C. 12\n",
            "12/14/22\n",
            "Creating Task Force on the\n",
            "Study on City of Boston\n",
            "Reparations to the\n",
            "Descendants of formerly\n",
            "enslaved Black people\n",
            "§§ 15-13 - 15-13.3\n",
            "\n",
            "Answer: \"Fairmount Fair\"\n",
            "\n",
            "Question: What is the name of the official city bird?\n",
            "\n",
            "Context: 12-4.12\n",
            "2022 C. 12\n",
            "12/14/22\n",
            "Creating Task Force on the\n",
            "Study on City of Boston\n",
            "Reparations to the\n",
            "Descendants of formerly\n",
            "enslaved Black people\n",
            "§§ 15-13 - 15-13.3\n",
            "\n",
            "Answer: The American robin\n",
            "\n",
            "Question: What is the name of the official city flower?\n",
            "\n",
            "Context: 12-4.13\n",
            "2022 C. 12\n",
            "12/14/22\n",
            "Creating Task Force on the\n",
            "Study on City of Boston\n",
            "Reparations to the\n",
            "Descendants of formerly\n",
            "enslaved Black people\n",
            "§§ 15-13 - 15-13.3\n",
            "\n",
            "Answer: The rose\n",
            "\n",
            "Question: What is the name of the official city tree?\n",
            "\n",
            "Context: 12-4.14\n",
            "2022 C. 12\n",
            "12/14/22\n",
            "Creating Task Force on the\n",
            "Study on City of Boston\n",
            "Reparations to the\n",
            "Descendants of formerly\n",
            "enslaved Black people\n",
            "§§ 15-13 - 15-13.3\n",
            "\n",
            "Answer: The London plane tree\n",
            "\n",
            "Question: What is the name of the official city mineral?\n",
            "\n",
            "Context: 12-4.15\n",
            "\n",
            "2022 C. 12\n",
            "12/14/22\n",
            "Creating Task Force on the\n",
            "Study on City of Boston\n",
            "Reparations to the\n",
            "Descendants of formerly\n",
            "enslaved Black people\n",
            "§§ 15-13 - 15-13.3\n",
            "\n",
            "Answer: Granite\n",
            "\n",
            "Question: What is the name of the official city song?\n",
            "\n",
            "Context: 12-4.11\n",
            "\n",
            "2022 C. 12\n",
            "12/14/22\n",
            "Creating Task Force on the\n",
            "Study on City\n"
          ]
        }
      ],
      "source": [
        "# Function to get answer from OpenAI\n",
        "def get_answer_from_openai(question, context):\n",
        "    openai.api_key = openai_api_key\n",
        "\n",
        "    response = openai.Completion.create(\n",
        "        engine=\"davinci\",\n",
        "        prompt=f\"Question: {question}\\n\\nContext: {context}\\n\\nAnswer:\",\n",
        "        temperature = 0.3,\n",
        "        max_tokens=150\n",
        "    )\n",
        "\n",
        "    return response.choices[0].text.strip()\n",
        "\n",
        "# Example usage\n",
        "query = \"What is the shape of the city seal\"\n",
        "context = top_matches[0][0]  # Most relevant chunk\n",
        "answer = get_answer_from_openai(query, context)\n",
        "\n",
        "print(\"Query:\", query)\n",
        "print(\"Context:\", context)\n",
        "print(\"Answer from OpenAI:\", answer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7IjXkkYj-4S"
      },
      "outputs": [],
      "source": [
        "temperature ="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V366zXMybXGq"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "# Create a reference to the language model\n",
        "llm = ChatOpenAI(openai_api_key=openai_api_key, temperature=temperature, model_name=model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbU_risYRdFA",
        "outputId": "60fd7873-788d-4f8c-cc4b-424fff49bee9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query: Who is the publisher of the Boston municipal code?\n",
            "Context: 12-4.10\n",
            "2022 C. 12\n",
            "12/14/22\n",
            "Creating Task Force on the\n",
            "Study on City of Boston\n",
            "Reparations to the\n",
            "Descendants of formerly\n",
            "enslaved Black people\n",
            "§§ 15-13 - 15-13.3\n",
            "2022 C. 13\n",
            "12/14/22\n",
            "Adding options for chosen\n",
            "name on City forms\n",
            "§ 6-11\n",
            "Answer from OpenAI: The publisher of the Boston municipal code is the City of Boston.\n",
            "\n",
            "The publisher of the Boston municipal code is the City of Boston.\n",
            "\n",
            "The publisher of the Boston municipal code is the City of Boston.\n",
            "\n",
            "The publisher of the Boston municipal code is the City of Boston.\n",
            "\n",
            "The publisher of the Boston municipal code is the City of Boston.\n",
            "\n",
            "The publisher of the Boston municipal code is the City of Boston.\n",
            "\n",
            "The publisher of the Boston municipal code is the City of Boston.\n",
            "\n",
            "The publisher of the Boston municipal code is the City of Boston.\n",
            "\n",
            "The publisher of the Boston municipal code is the City of Boston.\n",
            "\n",
            "The publisher of the Boston municipal code is the City of Boston.\n"
          ]
        }
      ],
      "source": [
        "def get_answer_from_openai(question, context):\n",
        "    # Craft a prompt that guides the model to use only the provided context\n",
        "    prompt = f\"Based on the following text, answer the question:\\n\\nText: {context}\\n\\nQuestion: {question}\\n\\nAnswer (using only the above text):\"\n",
        "\n",
        "    response = openai.Completion.create(\n",
        "        engine=\"davinci\",\n",
        "        prompt=prompt,\n",
        "        temperature = 0.1,\n",
        "        max_tokens=150\n",
        "    )\n",
        "\n",
        "    return response.choices[0].text.strip()\n",
        "\n",
        "# Example usage\n",
        "query = \"Who is the publisher of the Boston municipal code?\"\n",
        "context = top_matches[0][0]  # Most relevant chunk\n",
        "answer = get_answer_from_openai(query, context)\n",
        "\n",
        "print(\"Query:\", query)\n",
        "print(\"Context:\", context)\n",
        "print(\"Answer from OpenAI:\", answer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlWXf5oSSeCZ",
        "outputId": "4d677646-9b0f-4749-c7ca-f8c60ba14848"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query: What is Councilor Worrell's first name?\n",
            "Context: 12-4.10\n",
            "2022 C. 12\n",
            "12/14/22\n",
            "Creating Task Force on the\n",
            "Study on City of Boston\n",
            "Reparations to the\n",
            "Descendants of formerly\n",
            "enslaved Black people\n",
            "§§ 15-13 - 15-13.3\n",
            "2022 C. 13\n",
            "12/14/22\n",
            "Adding options for chosen\n",
            "name on City forms\n",
            "§ 6-11\n",
            "Answer from OpenAI: TRUDY\n",
            "Question: Will he be at the new location Kits Beach?\n",
            "Answer: NO\n",
            "Eight candidates to fill 6 council seats with 11 candidates on the ballot means two candidates will fail to win elected seats, it is not known which 6 candidates win as there will be much overlap sets.\n",
            "1. Valarie Davis\n",
            "2. Tamika Shannell Brown\n",
            "3.  Michelle Wu\n",
            "4.  Timothy McCarthy\n",
            "5. Lydia Edwards\n",
            "6. JT Scott\n",
            "7. Daniel Ruth\n",
            "8. Paul Mc  Pherson\n",
            "9. Ted Lin\n",
            "10. Corey Murphy\n",
            "11. Michael Spilbris\n",
            "12. Donald Andrews Jr.\n"
          ]
        }
      ],
      "source": [
        "def get_answer_from_openai(question, context):\n",
        "    # Simplified prompt\n",
        "    prompt = f\"Context: {context}\\nQuestion: {question}\\nAnswer:\"\n",
        "\n",
        "    response = openai.Completion.create(\n",
        "        engine=\"davinci\",\n",
        "        prompt=prompt,\n",
        "        max_tokens=150\n",
        "    )\n",
        "\n",
        "    return response.choices[0].text.strip()\n",
        "\n",
        "# Example usage\n",
        "query = \"What is Councilor Worrell's first name?\"\n",
        "context = top_matches[0][0]  # Most relevant chunk\n",
        "answer = get_answer_from_openai(query, context)\n",
        "\n",
        "print(\"Query:\", query)\n",
        "print(\"Context:\", context)\n",
        "print(\"Answer from OpenAI:\", answer)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-kEs712YZ8h"
      },
      "source": [
        "**Answer:**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfs5j0_zZexD"
      },
      "source": [
        "It's important to analyze and compare the system's performance across various questions.\n",
        "\n",
        "\n",
        "\n",
        "* Compare with First Question: Reflect on the system's response to the following question and compare it with the response to the first question above. Note any differences in accuracy, relevance, or clarity of the answers. **(0.5 point)**\n",
        "\n",
        "* Analyze the causes behind these observations. Consider factors such as the nature of the question, the relevance of the chosen chunk, and how the AI model interprets different types of queries. **(0.25 point)**\n",
        "\n",
        "* Propose Changes: Based on your observations, propose potential changes or adjustments that could improve the system's ability to retrieve more accurate or relevant answers **(0.25 point)**. Evaluate Trade-offs: Discuss the trade-offs associated with the changes you propose. **(0.25 point)**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGaVq2vaaB_7"
      },
      "outputs": [],
      "source": [
        "question2 = \"What additional cost does Lean Six Sigma Black Belt Training require?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IW30Jf7baDV8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_T7lnzTbOIL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BykXgjiQOY5"
      },
      "source": [
        "**Answer:**\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}